{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from glom import glom\n",
    "import pandas as pd\n",
    "import fitz # pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the XML export from Papers 3: \"EndNote XML Library\"\n",
    "path_xml = Path('~/Downloads/temp-papers-export-tidy.xml').expanduser()\n",
    "# export from Papers 3 \"PDF Files and Media\", without annotation\n",
    "path_original = Path('~/Downloads/temp-papers-export-original').expanduser()\n",
    "# export from Papers 3 \"PDF Files and Media\", with annotation\n",
    "path_annotated = Path('~/Downloads/temp-papers-export').expanduser()\n",
    "# input path of the library file\n",
    "# it can be the same as the path_xml, or another one such as RIS or BibTeX\n",
    "in_path = path_xml\n",
    "# output path of the modified library file, extension should be the same as in_path\n",
    "out_path = Path('~/Downloads/temp-papers-export-annotated.xml').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(fname):\n",
    "    '''https://stackoverflow.com/a/3431838'''\n",
    "    import hashlib\n",
    "\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_annotation(path):\n",
    "    doc = fitz.open(path)\n",
    "    result = any(bool(doc[i].firstAnnot) for i in range(doc.pageCount))\n",
    "    doc.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_info(df):\n",
    "    '''get all info from df.path, inplace.\n",
    "    '''\n",
    "    df['md5'] = df.path.map(md5)\n",
    "    df['size'] = df.path.map(os.path.getsize)\n",
    "    df['stem'] = df.path.map(lambda x: x.stem)\n",
    "    df['has_annotation'] = df.path.map(has_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate(df, col):\n",
    "    '''detect duplicate of df[col]'''\n",
    "    df_col = df[col]\n",
    "    df_temp = df_col.value_counts()\n",
    "    return df[df_col.isin(df_temp[df_temp > 1].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers XML export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_xml, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = glom(xmltodict.parse(text), 'xml.records.record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_xml = (\n",
    "    Path(path.replace('file://localhost', '', 1))\n",
    "    for path in (glom(record, 'urls.pdf-urls.url.style.#text', default=None) for record in records)\n",
    "    if path is not None\n",
    ")\n",
    "# only process pdf files. In principle other combination exists: Pdf, pDF, etc.\n",
    "df_xml = pd.DataFrame((path for path in paths_xml if path.suffix in ('.pdf', '.PDF')), columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_info(df_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = get_duplicate(df_xml, 'md5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup.sort_values('md5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure nothing is duplicated\n",
    "assert df_dup.size == 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_xml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers PDF export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame(list(chain(path_original.glob('*.pdf'), path_original.glob('*.PDF'))), columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_info(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure nothing is duplicated\n",
    "# assert get_duplicate(df_original, 'md5').size == 0\n",
    "# somehow there might be some duplicates from here\n",
    "# it doesn't need to be drop. After a merge below, there will be\n",
    "# multiple rows for these md5. In the replace process at the end,\n",
    "# only the first will actually replace something.\n",
    "get_duplicate(df_original, 'md5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(chain(path_annotated.glob('*.pdf'), path_annotated.glob('*.PDF'))), columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure nothing is duplicated\n",
    "# assert get_duplicate(df, 'md5').size == 0\n",
    "# somehow there might be some duplicates from here\n",
    "# it doesn't need to be drop. After a merge below, there will be\n",
    "# multiple rows for these md5. In the replace process at the end,\n",
    "# only the first will actually replace something.\n",
    "get_duplicate(df, 'md5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original and Annotated merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_original, df, on='stem', suffixes=('_original', '_annotated'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the original and annotated directories are indentical in filenames\n",
    "assert df_merge.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prove that all PDFs are transformed (regardless if it is annotated)\n",
    "assert df_merge[df_merge.md5_original == df_merge.md5_annotated].size == 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showing how much size has inflated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_merge.size_annotated / df_merge.size_original).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "df_merge.size_annotated.sum() / df_merge.size_original.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_all = pd.merge(df_xml, df_merge, left_on='md5', right_on='md5_original', suffixes=('_library', ''))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_merge_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_all.has_annotation_annotated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_path != path_xml:\n",
    "    with open(in_path, 'r') as f:\n",
    "        text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace original path in XML to the path of the annotated file\n",
    "for path_in, path_out in df_merge_all.loc[df_merge_all.has_annotation_annotated, ('path', 'path_annotated')].values:\n",
    "    text = text.replace(str(path_in), str(path_out), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'w') as f:\n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all3-defaults",
   "language": "python",
   "name": "all3-defaults"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
